# Batch Training Module

Resources created

1. 3x SSM parameters
2. 3x DDB
3. 5x Glue Jobs

## Sample input

Below is the sample input which is accepted by step function. All of it will be dynamically generated by Jenkins Pipeline.

```hcl
step_function_inputs = {
  "inference_inputs" = {
    "athena_pred_or_eval_table_name" = "evaluation"
    "athenadb_name" = "default"
    "aws_batch_job_name" = "jenkins-pl-apsouth1-job"
    "aws_batch_job_queue" = "jenkins-pl-apsouth1-dapf-batch-inferencing-job-queue"
    "dq_athena_db" = "jenkins_pl_apsouth1_data_quality"
    "dq_table" = "dqresults"
    "inference_athenadb_debug_table_name" = "debug_infernence"
    "inference_athenadb_inference_table_name" = "inference"
    "inference_athenadb_metadata_table_name" = "meta_inference"
    "inference_athenadb_name" = "default"
    "inference_inputtable_name" = "jenkins-pl-apsouth1-inferencing-input-table"
    "inference_metatable_name" = "jenkins-pl-apsouth1-inferencing-meta-table"
    "inference_statetable_name" = "jenkins-pl-apsouth1-inferencing-state-table"
    "inferencing_event_bus_name" = "jenkins-pl-apsouth1-dapf-cb"
    "mapping_json_S3_path" = "s3://jenkins-pl-apsouth1-inferencing-internal/mapping_json/mapping_json.json"
    "region" = "ap-south-1"
    "repository" = "proserve-india/projects/etip/maruti-modelops/template-bu-use-case-dapm-framework"
    "s3_bucket_name_internal" = "jenkins-pl-apsouth1-inferencing-internal"
    "s3_bucket_name_shared" = "jenkins-pl-apsouth1-inferencing-shared"
    "sns_topic_arn" = "arn:aws:sns:ap-south-1:731580992380:jenkins-pl-apsouth1-dapf-notifier"
    "ssm_approved_model_prefix_path" = "approved_model_prefix_path"
    "ssm_inferencing_complete_status" = "/jenkins-pl-apsouth1-dapf-ssm/inferencing/inferencing_complete_status"
    "ssm_winning_algo_name" = "winner_algorithm"
    "step_function_arn" = "arn:aws:states:ap-south-1:731580992380:stateMachine:jenkins-pl-apsouth1-modelops-inferencing-orchestrator"
    "use_case_name" = "jenkins"
  }
  "ssm_params" = [
    "/jenkins-pl-apsouth1-dapf-ssm/inferencing_step_function_inputs",
    "/jenkins-pl-apsouth1-dapf-ssm/training_step_function_inputs",
  ]
  "training_inputs" = {
    "athena_pred_or_eval_table_name" = "evaluation"
    "athenadb_debug_table_name" = "debug"
    "athenadb_evaluation_summary_table_name" = "model_eval_summary"
    "athenadb_metadata_table_name" = "metatable"
    "athenadb_name" = "default"
    "aws_batch_job_name" = "jenkins-pl-apsouth1-job"
    "aws_batch_job_queue" = "jenkins-pl-apsouth1-dapf-batch-training-job-queue"
    "dq_athena_db" = "jenkins_pl_apsouth1_data_quality"
    "dq_table" = "dqresults"
    "mapping_json_S3_path" = "s3://jenkins-pl-apsouth1-training-internal/mapping_json/mapping_json.json"
    "model_package_group_name" = "jenkins-pl-apsouth1-dapf-mpg"
    "region" = "ap-south-1"
    "repository" = "proserve-india/projects/etip/maruti-modelops/template-bu-use-case-dapm-framework"
    "s3_bucket_name_internal" = "jenkins-pl-apsouth1-training-internal"
    "s3_bucket_name_shared" = "jenkins-pl-apsouth1-training-shared"
    "sns_topic_arn" = "arn:aws:sns:ap-south-1:731580992380:jenkins-pl-apsouth1-dapf-notifier"
    "ssm_training_complete_status" = "/jenkins-pl-apsouth1-dapf-ssm/training/training_complete_status"
    "step_function_arn" = "arn:aws:states:ap-south-1:731580992380:stateMachine:jenkins-pl-apsouth1-modelops-training-orchestrator"
    "train_inputtable_name" = "jenkins-pl-apsouth1-training-input-table"
    "train_metatable_name" = "jenkins-pl-apsouth1-training-meta-table"
    "train_statetable_name" = "jenkins-pl-apsouth1-training-state-table"
    "training_event_bus_name" = "jenkins-pl-apsouth1-dapf-cb"
    "use_case_name" = "jenkins"
  }
}
```

1. Apply Analytics with `-target` options. This is required because Glue workflow donot support parallel trigger deployments.
Hence we bypass this problem, by target deployment of `module.analytics_etl`. This is also the behaviour implemented in jenkins pipeline.

```bash

```

Here's a sample error

```hcl

```
